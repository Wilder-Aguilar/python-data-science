# -*- coding: utf-8 -*-
"""importacionDatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ooHkhIVohB2nUHNui60m18XW77kKuarl

# Adquisición de datos
<p>
Un conjunto de datos es normalmente un archivo que contiene datos almacenados en uno de varios formatos. Los formatos de archivo más comunes que contienen conjuntos de datos son: .csv, .json, .xlsx, etc. El conjunto de datos puede almacenarse en diferentes lugares, en su equipo local, en un servidor o sitio web, en un almacenamiento en la nube, etc.
Para analizar datos en un cuaderno de Python, necesitamos importar el conjunto de datos al cuaderno. En esta sección, aprenderás a cargar un conjunto de datos en nuestro cuaderno Jupyter.

En nuestro caso, el conjunto de datos Automobile Data es una fuente en línea y está en formato CSV (valores separados por comas). Usemos este conjunto de datos como ejemplo para practicar la lectura de datos.
<ul>
    <li>Data source: <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data" target="_blank">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a></li>
    <li>Data type: csv</li>
</ul>
La biblioteca Pandas es una herramienta muy popular y útil que nos permite leer diversos conjuntos de datos en un marco de datos; nuestras plataformas Jupyter Notebook tienen una biblioteca Pandas integrada, por lo que solo tenemos que importar Pandas sin necesidad de instalarla.
</p>
"""

# import pandas library
import pandas as pd
import numpy as np
import matplotlib.pylab as plt

"""<h2>LEER DATOS</h2>
<p>
Utilizamos la función <code>pandas.read_csv()</code> para leer archivos CSV. Sin embargo, en esta versión del laboratorio, que funciona en JupyterLite, el conjunto de datos debe descargarse en la interfaz utilizando el código que se proporciona a continuación.
</p>
"""

filepath = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv"
df = pd.read_csv(filepath, header=None)

"""Después de leer el conjunto de datos, podemos utilizar el <code>data_frame.head(n)</code> método para comprobar las n primeras filas del marco de datos, donde n es un número entero. Contrariamente a  <code>data_frame.head(n)</code>, <code>data_frame.tail(n)</code> le mostrará las n filas inferiores del marco de datos."""

# show the first 5 rows using dataframe.head() method
print("The first 5 rows of the dataframe")
df.head(5)

"""<div class="alert alert-danger alertdanger" style="margin-top: 20px">
<h1> Pregunta #1: </h1>
<b>Comprueba las 10 filas inferiores del marco de datos. "df".</b>
</div>
"""

print("lLas ultimas 10 filas del marco de datos\n")
df.tail(10)

"""<h3>Añadir encabezados</h3>
<p>
Echa un vistazo al conjunto de datos. Pandas establece automáticamente el encabezado con un número entero que comienza por 0.
</p>
<p>
Para describir mejor los datos, puede introducir un encabezado. Esta información está disponible en:  <a href="https://archive.ics.uci.edu/ml/datasets/Automobile" target="_blank">https://archive.ics.uci.edu/ml/datasets/Automobile</a>.
</p>
<p>
Por lo tanto, hay que añadir los encabezados manualmente.
</p>
<p>
En primer lugar, cree una lista "headers" que incluya todos los nombres de las columnas en orden.
A continuación, utilice <code>dataframe.columns = headers</code> para sustituir los encabezados por la lista que ha creado.
</p>
"""

# create headers list
headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
         "drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
         "num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
         "peak-rpm","city-mpg","highway-mpg","price"]
print("headers\n", headers)

""" Reemplazar los encabezados y volver a comprobar nuestro marco de datos:"""

df.columns = headers
df.columns

"""También puede ver las primeras 10 entradas del marco de datos actualizado y observar que los encabezados se han actualizado."""

df.head(10)

"""Ahora, tenemos que sustituir el símbolo «?» por NaN para que dropna() pueda eliminar los valores que faltan:"""

df1=df.replace('?',np.nan)
df1.head(20)

"""Puede eliminar los valores que faltan en la columna «precio» de la siguiente manera:"""

df=df1.dropna(subset=["price"], axis=0)
df.head(20)

"""Aquí, «axis=0» significa que el contenido de toda la fila se eliminará siempre que la entidad «price» sea NaN.

Ahora ya ha leído correctamente el conjunto de datos sin procesar y ha añadido los encabezados correctos al marco de datos.

<div class="alert alert-danger alertdanger" style="margin-top: 20px">
<h1> Pregunta #2: </h1>
<b>Busca el nombre de las columnas del marco de datos.</b>
</div>
"""

print(df.columns)

"""<h2>Guardar conjunto de datos</h2>
<p>
Del mismo modo, Pandas te permite guardar el conjunto de datos en formato CSV. Mediante el método <code>dataframe.to_csv()</code>, puedes añadir la ruta y el nombre del archivo entre comillas dentro de los corchetes.
</p>
<p>
Por ejemplo, si guardas el marco de datos <b>df</b> as <b>automobile.csv</b> a su máquina local, puede utilizar la sintaxis siguiente, donde <code>index = False</code> significa que los nombres de las filas no se escribirán.
</p>
"""

df.to_csv("automobile.csv", index=False)

"""También puede leer y guardar otros formatos de archivo. Puede utilizar funciones similares como **`pd.read_csv()`** y **`df.to_csv()`** para otros formatos de datos. Las funciones se enumeran en la siguiente tabla:

<h2>Leer/Guardar otros formatos de datos</h2>

| Data Formate |        Read       |            Save |
| ------------ | :---------------: | --------------: |
| csv          |  `pd.read_csv()`  |   `df.to_csv()` |
| json         |  `pd.read_json()` |  `df.to_json()` |
| excel        | `pd.read_excel()` | `df.to_excel()` |
| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |
| sql          |  `pd.read_sql()`  |   `df.to_sql()` |
| ...          |        ...        |             ... |

# Información básica del conjunto de datos
<p>
Después de leer los datos en el marco de datos Pandas, es el momento de explorar el conjunto de datos.<br>

Hay varias formas de obtener información esencial de los datos que le ayudarán a comprenderlos mejor.
</p>

<h2>Tipos de datos</h2>
<p>
Los datos tienen diversos tipos.<br>
Los principales tipos almacenados en los marcos de datos de Pandas son <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. Para comprender mejor cada atributo, siempre debes conocer el tipo de datos de cada columna. En Pandas:
</p>
"""

df.dtypes

"""Devuelve una serie con el tipo de datos de cada columna."""

# Comprueba el tipo de datos del marco de datos «df» mediante .dtypes.
print(df.dtypes)

"""<p>
Como se muestra arriba, se puede ver claramente que el tipo de datos de «symboling» y «curb-weight» son  <code>int64</code>, "normalized-losses" is <code>object</code>, and "wheel-base" is <code>float64</code>, etc.
</p>
<p>
Estos tipos de datos se pueden cambiar; aprenderás cómo hacerlo en un módulo posterior.
</p>

<h2>Describir</h2>
Si queremos obtener un resumen estadístico de cada columna, como el recuento, el valor medio de la columna, la desviación estándar de la columna, etc., utilice el método describe:

Este método proporcionará diversas estadísticas resumidas, excluyendo los valores <code>NaN</code> (No es un número).

dataframe.describe()

<p>
Esto muestra el resumen estadístico de todas las columnas de tipo numérico (int, float).<br>

Por ejemplo, el atributo «symboling» tiene 205 recuentos, el valor medio de esta columna es 0,83, la desviación estándar es 1,25, el valor mínimo es -2, el percentil 25 es 0, el percentil 50 es 1, el percentil 75 es 2 y el valor máximo es 3.
<br>

Sin embargo, ¿qué pasaría si también quisieras comprobar todas las columnas, incluidas las que son de tipo objeto?
<br><br>

Puedes añadir un argumento <code>include = «all»</code> dentro del corchete. Inténtalo de nuevo.

</p>
"""

# describe all the columns in "df"
df.describe(include = "all")

"""<p>
Ahora proporciona el resumen estadístico de todas las columnas, incluidos los atributos de tipo objeto.<br>
Ahora puede ver cuántos valores únicos hay, cuál es el valor más frecuente y la frecuencia del valor más frecuente en las columnas de tipo objeto.
Algunos valores de la tabla anterior muestran «NaN». Esos números no están disponibles en relación con un tipo de columna concreto.
</p>

<div class="alert alert-danger alertdanger" style="margin-top: 20px">
<h1> Pregunta #3: </h1>

<p>
Puede seleccionar las columnas de un marco de datos indicando el nombre de cada columna. Por ejemplo, puede seleccionar las tres columnas de la siguiente manera:
</p>
<p>
    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>
</p>
<p>
Donde «column» es el nombre de la columna, puede aplicar el método «.describe()» para obtener las estadísticas de esas columnas de la siguiente manera:
</p>
<p>
    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>
</p>

Aplica el método «.describe()» a las columnas 'length' y  'compression-ratio'.

</div>
"""

df[['length','compression-ratio']].describe()

"""<h2>Información</h2>
También puede utilizar otro método para comprobar su conjunto de datos:

dataframe.info()

Proporciona un resumen conciso de su marco de datos.

Este método imprime información sobre un marco de datos, incluyendo el tipo de índice y las columnas, los valores no nulos y el uso de memoria.
"""

# look at the info of "df"
df.info()

"""# Manipulación de datos

<h2>¿Cuál es el propósito del procesamiento de datos?</h2>

El procesamiento de datos se utiliza para convertir datos de un formato inicial a un formato que puede ser más adecuado para su análisis.

<h3>¿Cuál es el consumo de combustible (L/100 km) del coche diésel?</h3>

<h4>Evaluación de datos faltantes</h4>
Los valores perdidos se convierten de forma predeterminada. Utilice las siguientes funciones para identificar estos valores perdidos. Puede utilizar dos métodos para detectar datos perdidos:
<ol>
    <li><b>.isnull()</b></li>
    <li><b>.notnull()</b></li>
</ol>
El resultado es un valor booleano que indica si el valor que se pasa al argumento es, de hecho, un dato faltante.
"""

missing_data = df.isnull()
missing_data.head(5)

"""«True» significa que el valor es un valor perdido, mientras que «False» significa que el valor no es un valor perdido.

<h4>Contar los valores faltantes en cada columna</h4>
<p>
Utilizando un bucle «for» en Python, puede averiguar rápidamente el número de valores perdidos en cada columna. Como se ha mencionado anteriormente, «True» representa un valor perdido y «False» significa que el valor está presente en el conjunto de datos.  En el cuerpo del bucle «for», el método «.value_counts()» cuenta el número de valores «True».
</p>
"""

for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")

"""### Cómo tratar los datos faltantes
<b>¿Cómo se deben tratar los datos faltantes?</b>

<ol>
    <li>Eliminar datos<br>
        a. Eliminar toda la fila<br>
        b. Eliminar toda la columna
    </li>
    <li>Reemplazar datos<br>
        a. Reemplazar por la media<br>
        b. Reemplazar por la frecuencia<br>
        c. Reemplazar basándose en otras funciones
    </li>
</ol>

Solo debe eliminar columnas completas si la mayoría de las entradas de la columna están vacías. En el conjunto de datos, ninguna de las columnas está lo suficientemente vacía como para eliminarla por completo.
Tienes cierta libertad para elegir el método con el que sustituir los datos; sin embargo, algunos métodos pueden parecer más razonables que otros. Aplica cada método a diferentes columnas:

<b>Sustituir por la media:</b>
<ul>
    <li>«normalized-losses»: 41 datos faltantes, sustituirlos por la media</li>
    <li>«stroke»: 4 datos faltantes, sustituirlos por la media</li>
    <li>«bore»: 4 datos faltantes, reemplazarlos por la media</li>
    <li>«horsepower»: 2 datos faltantes, reemplazarlos por la media</li>
    <li>«peak-rpm»: 2 datos faltantes, reemplazarlos por la media</li>
</ul>

<b>Sustituir por frecuencia:</b>
<ul>
    <li>«num-of-doors»: 2 datos faltantes, sustituirlos por «cuatro».
        <ul>
            <li>Motivo: el 84 % de los sedanes son de cuatro puertas. Dado que cuatro puertas es lo más frecuente, es lo más probable que ocurra</li>
        </ul>
    </li>
</ul>

<b>Eliminar toda la fila:</b>
<ul>
    <li>«precio»: faltan 4 datos, simplemente elimine toda la fila
        <ul>
            <li>Motivo: desea predecir el precio. No puede utilizar ninguna entrada de datos sin datos de precio para la predicción; por lo tanto, cualquier fila que ahora no tenga datos de precio no le resulta útil.</li>
        </ul>
    </li>
</ul>

<h4>Calcular el valor medio de la columna «pérdidas normalizadas» </h4>
"""

avg_norm_loss = df["normalized-losses"].astype("float").mean(axis=0)
print("Average of normalized-losses:", avg_norm_loss)

"""<h4>Reemplazar «NaN» por el valor medio en la columna «pérdidas normalizadas»</h4>"""

df.loc[:, "normalized-losses"] = df["normalized-losses"].replace(np.nan, avg_norm_loss)

df.head(5)

"""<h4>Calcular el valor medio de la columna «bore»</h4>"""

avg_bore=df['bore'].astype('float').mean(axis=0)
print("Average of bore:", avg_bore)

"""<h4>Reemplazar «NaN» por el valor medio de la columna «bore»</h4>"""

df.loc[:, "bore"] = df["bore"].replace(np.nan, avg_bore)

"""Calcular el valor medio de la columna «stroke»"""

avg_stroke=df['stroke'].astype('float').mean(axis=0)
print("Average of stroke:", avg_stroke)

"""Reemplazar «NaN» por el valor medio de la columna «stroke»"""

df.loc[:, "stroke"] = df["stroke"].replace(np.nan, avg_stroke)
df.head(5)

"""Calcular el valor medio de la columna 'horsepower'"""

avg_horsepower = df['horsepower'].astype('float').mean(axis=0)
print("Average horsepower:", avg_horsepower)

df.loc[:, 'horsepower'] = df['horsepower'].replace(np.nan, avg_horsepower)

df.head(3)

"""Calcular el valor medio de la columna 'peak-rpm'"""

avg_peakrpm=df['peak-rpm'].astype('float').mean(axis=0)
print("Average peak rpm:", avg_peakrpm)

"""Reemplazar «NaN» por el valor medio de la columna 'peak-rpm'"""

df.loc[:, 'peak-rpm'] = df['peak-rpm'].replace(np.nan, avg_peakrpm)

df.head(3)

"""Para ver qué valores hay en una columna concreta, podemos usar el método «.value_counts()»:"""

df['num-of-doors'].value_counts()

"""Como se puede ver, el tipo más común es el de cuatro puertas. También podemos utilizar el método «.idxmax()» para calcular automáticamente el tipo más común:"""

df['num-of-doors'].value_counts().idxmax()

"""El procedimiento de sustitución es muy similar al que ha visto anteriormente:"""

#replace the missing 'num-of-doors' values by the most frequent

df.loc[:, 'num-of-doors'] = df['num-of-doors'].replace(np.nan, 'four')

"""Por último, elimina todas las filas que no tengan datos de precio:"""

# simplemente elimina toda la fila con NaN en la columna «precio»
df = df.dropna(subset=["price"], axis=0)

# Restablecer el índice, porque hemos eliminado dos filas.
df.reset_index(drop=True, inplace=True)

df.head()

"""¡Bien! Ahora tienes un conjunto de datos sin valores perdidos.

### Formato de datos correcto
<b>¡Ya casi estamos!</b>
<p>El último paso en la limpieza de datos es comprobar y asegurarse de que todos los datos están en el formato correcto (entero, flotante, texto u otro).</p>

En Pandas, se utiliza:
<p><b>.dtype()</b> para comprobar el tipo de datos</p>
<p><b>.astype()</b> para cambiar el tipo de datos</p>

<h4>Enumeremos los tipos de datos para cada columna</h4>
"""

df.dtypes

"""<p>Como puede ver arriba, algunas columnas no tienen el tipo de datos correcto. Las variables numéricas deben ser de tipo «float» o «int», y las variables con cadenas, como las categorías, deben ser de tipo «object». Por ejemplo, los valores numéricos «bore» y «stroke» describen los motores, por lo que cabría esperar que fueran de tipo «float» o «int»; sin embargo, se muestran como tipo «object». Debe convertir los tipos de datos al formato adecuado para cada columna utilizando el método «astype()».</p>

<h4>Convertir los tipos de datos al formato adecuado</h4>
"""

df[["bore", "stroke"]] = df[["bore", "stroke"]].astype("float")
df[["normalized-losses"]] = df[["normalized-losses"]].astype("int")
df[["price"]] = df[["price"]].astype("float")
df[["peak-rpm"]] = df[["peak-rpm"]].astype("float")

"""<h4>Enumeremos las columnas después de la conversión</h4>"""

df.dtypes

"""¡Genial!

Ahora por fin tienes el conjunto de datos limpio, sin valores perdidos y con todos los datos en el formato correcto.

## Estandarización de datos
<p>
Normalmente se recopilan datos de diferentes organismos en diferentes formatos.
(La estandarización de datos también es un término que se utiliza para referirse a un tipo concreto de normalización de datos en el que se resta la media y se divide por la desviación estándar).
</p>
    
<b>¿Qué es la estandarización?</b>
<p>La estandarización es el proceso de transformar los datos a un formato común, lo que permite al investigador realizar comparaciones significativas.
</p>

<b>Ejemplo</b>
<p>Transformar mpg a L/100 km:</p>
<p>En su conjunto de datos, las columnas de consumo de combustible «city-mpg» y «highway-mpg» se representan en unidades mpg (millas por galón). Supongamos que está desarrollando una aplicación en un país que acepta el consumo de combustible con el estándar L/100 km.
</p>
<p>Deberá aplicar una <b>transformación de datos</b> para convertir mpg a L/100 km.

<p>Utiliza esta fórmula para la conversión de unidades:<p>
L/100 km = 235 / mpg
<p>Puedes realizar muchas operaciones matemáticas directamente con Pandas.</p>
"""

df.head()

# Convert mpg to L/100km by mathematical operation (235 divided by mpg)
df['city-L/100km'] = 235/df["city-mpg"]

# check your transformed data
df.head()

"""<b>Según el ejemplo anterior, convierta mpg a L/100 km en la columna «highway-mpg» y cambie el nombre de la columna a «highway-L/100 km».</b>"""

df['highway-mpg'] = 235/df['highway-mpg']
df.rename(columns={'highway-mpg':'highway-L/100km'}, inplace=True)
df.head()

"""## Normalización de datos

<b>¿Por qué normalizar?</b>
<p>La normalización es el proceso de transformar los valores de varias variables en un rango similar. Las normalizaciones típicas incluyen
<ol>
    <li>escalar la variable para que su promedio sea 0</li>
    <li>escalar la variable para que la varianza sea 1</li>
    <li>escalar la variable para que los valores de la variable oscilen entre 0 y 1</li>
</ol>
</p>

<b>Ejemplo</b>
<p>Para demostrar la normalización, supongamos que desea escalar las columnas «longitud», «anchura» y «altura».</p>
<p><b>Objetivo:</b> normalizar esas variables para que su valor oscile entre 0 y 1</p>
<p><b>Enfoque:</b> sustituir el valor original por (valor original)/(valor máximo)</p>
"""

# replace (original value) by (original value)/(maximum value)
df['length'] = df['length']/df['length'].max()
df['width'] = df['width']/df['width'].max()

"""<b>Según el ejemplo anterior, normalice la columna «altura».</b>"""

df['height'] = df['height']/df['height'].max()
df.head()

df[["length","width","height"]].head()

"""Aquí has normalizado "length", "width" y "height" para que estén dentro del rango [0,1].

## Agrupación (Binning)
<b>¿Por qué agrupar?</b>
<p>
    La agrupación es un proceso que consiste en transformar variables numéricas continuas en «grupos» categóricos discretos para realizar un análisis agrupado.
</p>

<b>Ejemplo: </b>
<p>En su conjunto de datos, «horsepower» es una variable con valores reales que oscilan entre 48 y 288 y tiene 59 valores únicos. ¿Qué pasa si solo le interesa la diferencia de precio entre los coches con alta potencia, potencia media y poca potencia (3 tipos)? Puede reorganizarlos en tres «contenedores» para simplificar el análisis.

<p>Utilice el método «cut» de Pandas para segmentar la columna «potencia» en 3 contenedores.

<h3>Ejemplo de agrupación de datos en Pandas</h3>

Convertir los datos al formato correcto:
"""

df["horsepower"]=df["horsepower"].astype(int, copy=True)

"""Traza el histograma de la potencia para ver la distribución de la potencia."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib as plt
from matplotlib import pyplot
plt.pyplot.hist(df["horsepower"])

# set x/y labels and plot title
plt.pyplot.xlabel("horsepower")
plt.pyplot.ylabel("count")
plt.pyplot.title("horsepower bins")

"""<p>Encuentre 3 intervalos de igual tamaño utilizando la función <code>linspace(start_value, end_value, numbers_generated</code> de Numpy.</p>
<p>Dado que desea incluir el valor mínimo de potencia, establezca start_value = min(df[«horsepower»]).</p>
<p>Como desea incluir el valor máximo de potencia, establezca end_value = max(df[«horsepower»]).</p>
<p>Como está creando 3 intervalos de igual longitud, necesita 4 divisores, por lo que numbers_generated = 4.</p>

Cree una matriz de intervalos con un valor mínimo y un valor máximo utilizando el ancho de banda calculado anteriormente. Los valores determinarán cuándo termina un intervalo y cuándo comienza otro.
"""

bins = np.linspace(min(df["horsepower"]), max(df["horsepower"]), 4)
bins

"""Establecer nombres de grupos:"""

group_names = ['Low', 'Medium', 'High']

"""Aplica la función «cut» para determinar a qué pertenece cada valor de df[“horsepower”]."""

df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )
df[['horsepower','horsepower-binned']].head(20)

"""Vea el número de vehículos en cada contenedor:"""

df["horsepower-binned"].value_counts()

"""Traza la distribución de cada intervalo:"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib as plt
from matplotlib import pyplot
pyplot.bar(group_names, df["horsepower-binned"].value_counts())

# set x/y labels and plot title
plt.pyplot.xlabel("horsepower")
plt.pyplot.ylabel("count")
plt.pyplot.title("horsepower bins")

"""<p>
    Observe atentamente el cuadro de datos anterior. Verá que la última columna proporciona los intervalos para «caballos de fuerza» basados en tres categorías («Bajo», «Medio» y «Alto»).
</p>
<p>
    ¡Ha logrado reducir los intervalos de 59 a 3!
</p>

<h3>Visualización de intervalos</h3>
Normalmente, se utiliza un histograma para visualizar la distribución de los intervalos que hemos creado anteriormente.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib as plt
from matplotlib import pyplot


# draw historgram of attribute "horsepower" with bins = 3
plt.pyplot.hist(df["horsepower"], bins = 3)

# set x/y labels and plot title
plt.pyplot.xlabel("horsepower")
plt.pyplot.ylabel("count")
plt.pyplot.title("horsepower bins")

"""El gráfico anterior muestra el resultado del agrupamiento para el atributo «potencia».

## Variable indicadora
<b>¿Qué es una variable indicadora?</b>
<p>
    Una variable indicadora (o variable ficticia) es una variable numérica que se utiliza para etiquetar categorías. Se denominan «ficticias» porque los números en sí mismos no tienen un significado inherente.
</p>

<b>¿Por qué utilizar variables indicadoras?</b>
<p>
    Las variables indicadoras se utilizan para poder emplear variables categóricas en el análisis de regresión de los módulos posteriores.
</p>
<b>Ejemplo</b>
<p>
    La columna «fuel-type» tiene dos valores únicos: «gas» o «diesel». La regresión no entiende palabras, solo números. Para utilizar este atributo en el análisis de regresión, puede convertir «fuel-type» en variables indicadoras.
</p>

<p>
    Utilice el método Panda «get_dummies» para asignar valores numéricos a las diferentes categorías de tipo de combustible.
</p>
"""

df.columns

"""Obtenga las variables indicadoras y asígnelas al marco de datos «dummy_variable_1»:"""

dummy_variable_1 = pd.get_dummies(df["fuel-type"])
dummy_variable_1.head()

"""Cambia los nombres de las columnas para mayor claridad:"""

dummy_variable_1.rename(columns={'gas':'fuel-type-gas', 'diesel':'fuel-type-diesel'}, inplace=True)
dummy_variable_1.head()

"""En el marco de datos, la columna «fuel-type» (tipo de combustible) ahora tiene valores para «gas» y «diesel» como 0 y 1."""

# merge data frame "df" and "dummy_variable_1"
df = pd.concat([df, dummy_variable_1], axis=1)

# drop original column "fuel-type" from "df"
df.drop("fuel-type", axis = 1, inplace=True)

df.head()

"""Las dos últimas columnas son ahora la representación de la variable indicadora de la variable tipo de combustible. Ahora son todas ceros y unos.

<b>Al igual que antes, cree una variable indicadora para la columna «aspiration»</b>.
"""

dummy_variable_2 = pd.get_dummies(df["aspiration"])
dummy_variable_2.head()

dummy_variable_2.rename(columns={'std':'aspiration-std', 'turbo':'aspiration-turbo'}, inplace=True)
dummy_variable_2.head()

"""<b>Combina el nuevo marco de datos con el marco de datos original y, a continuación, elimina la columna «aspiration».</b>"""

# merge data frame "df" and "dummy_variable_2"
df = pd.concat([df, dummy_variable_2], axis=1)

# drop original column "aspiration" from "df"
df.drop("aspiration", axis = 1, inplace=True)

df.head()

"""Save the new csv:"""

df.to_csv('clean_df.csv')